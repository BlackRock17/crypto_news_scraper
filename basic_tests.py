import requests
from bs4 import BeautifulSoup


def test_coindesk_connection():
    """–ü—Ä–æ—Å—Ç —Ç–µ—Å—Ç –¥–∞–ª–∏ –º–æ–∂–µ–º –¥–∞ –¥–æ—Å—Ç–∏–≥–Ω–µ–º CoinDesk"""
    print("üîç –¢–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ –≤—Ä—ä–∑–∫–∞—Ç–∞ —Å CoinDesk...")

    url = "https://www.coindesk.com/"

    # –ù–∞—Å—Ç—Ä–æ–π–≤–∞–º–µ headers –∑–∞ –¥–∞ –∏–∑–≥–ª–µ–∂–¥–∞–º–µ –∫–∞—Ç–æ –±—Ä–∞—É–∑—ä—Ä
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    try:
        # –ü—Ä–∞–≤–∏–º GET –∑–∞—è–≤–∫–∞
        response = requests.get(url, headers=headers, timeout=10)

        # –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º–µ —Å—Ç–∞—Ç—É—Å –∫–æ–¥–∞
        print(f"üìä Status –∫–æ–¥: {response.status_code}")

        if response.status_code == 200:
            print("‚úÖ –£—Å–ø–µ—à–Ω–∞ –≤—Ä—ä–∑–∫–∞ —Å CoinDesk!")

            # –ü–∞—Ä—Å–∏—Ä–∞–º–µ HTML
            soup = BeautifulSoup(response.content, 'html.parser')

            # –ù–∞–º–∏—Ä–∞–º–µ –∑–∞–≥–ª–∞–≤–∏–µ—Ç–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ç–∞
            title = soup.find('title')
            if title:
                print(f"üìÑ –ó–∞–≥–ª–∞–≤–∏–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ç–∞: {title.text.strip()}")

            # –ù–∞–º–∏—Ä–∞–º–µ –≤—Å–∏—á–∫–∏ –ª–∏–Ω–∫–æ–≤–µ
            links = soup.find_all('a', href=True)

            # –¢—ä—Ä—Å–∏–º —Ä–∞–∑–ª–∏—á–Ω–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∏ –∑–∞ –Ω–æ–≤–∏–Ω–∞—Ä—Å–∫–∏ –ª–∏–Ω–∫–æ–≤–µ
            news_patterns = ['/news/', '/policy/', '/markets/', '/tech/', '/business/']
            all_news_links = []

            for link in links:
                href = link['href']
                if any(pattern in href for pattern in news_patterns):
                    all_news_links.append(link)

            # –°—ä—â–æ —Ç–∞–∫–∞ —Ç—ä—Ä—Å–∏–º –ª–∏–Ω–∫–æ–≤–µ, –∫–æ–∏—Ç–æ —Å—ä–¥—ä—Ä–∂–∞—Ç –∞–∫—Ç—É–∞–ª–Ω–∏ –Ω–æ–≤–∏–Ω–∏
            article_links = [link for link in links if
                             link.get('href', '').startswith('/') and len(link.text.strip()) > 20]

            print(f"üîó –ù–∞–º–µ—Ä–µ–Ω–∏ {len(links)} –æ–±—â–æ –ª–∏–Ω–∫–∞")
            print(f"üì∞ –ù–∞–º–µ—Ä–µ–Ω–∏ {len(all_news_links)} –Ω–æ–≤–∏–Ω–∞—Ä—Å–∫–∏ –ª–∏–Ω–∫–∞ —Å patterns")
            print(f"üìÑ –ù–∞–º–µ—Ä–µ–Ω–∏ {len(article_links)} –≤—ä–∑–º–æ–∂–Ω–∏ —Å—Ç–∞—Ç–∏–∏")

            # –ü–æ–∫–∞–∑–≤–∞–º–µ –ø—ä—Ä–≤–∏—Ç–µ 5 –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∏ –ª–∏–Ω–∫–∞
            print("\nüìã –ü—ä—Ä–≤–∏ 5 –≤—ä–∑–º–æ–∂–Ω–∏ —Å—Ç–∞—Ç–∏–∏:")
            for i, link in enumerate(article_links[:5], 1):
                href = link['href']
                text = link.text.strip()[:80] + "..." if len(link.text.strip()) > 80 else link.text.strip()
                print(f"  {i}. {text}")
                print(f"     ‚Üí {href}")

            print("\nüìã –ü—Ä–∏–º–µ—Ä–Ω–∏ –Ω–æ–≤–∏–Ω–∞—Ä—Å–∫–∏ –ª–∏–Ω–∫–æ–≤–µ:")
            for i, link in enumerate(all_news_links[:3], 1):
                href = link['href']
                text = link.text.strip()[:80] + "..." if len(link.text.strip()) > 80 else link.text.strip()
                print(f"  {i}. {text}")
                print(f"     ‚Üí {href}")

            assert len(links) > 0, "–¢—Ä—è–±–≤–∞ –¥–∞ –∏–º–∞ –ø–æ–Ω–µ –Ω—è–∫–æ–ª–∫–æ –ª–∏–Ω–∫–∞"
            print("\n‚úÖ –¢–µ—Å—Ç—ä—Ç –ø—Ä–µ–º–∏–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            return True

        else:
            print(f"‚ùå –ì—Ä–µ—à–∫–∞: –°—Ç–∞—Ç—É—Å –∫–æ–¥ {response.status_code}")
            return False

    except requests.exceptions.RequestException as e:
        print(f"‚ùå –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –≤—Ä—ä–∑–∫–∞—Ç–∞: {str(e)}")
        return False
    except Exception as e:
        print(f"‚ùå –ù–µ–æ—á–∞–∫–≤–∞–Ω–∞ –≥—Ä–µ—à–∫–∞: {str(e)}")
        return False


if __name__ == "__main__":
    print("=== –¢–ï–°–¢ –ù–ê COINDESK SCRAPER ===")
    success = test_coindesk_connection()

    if success:
        print("\nüéâ –û—Å–Ω–æ–≤–Ω–∏—è—Ç —Ç–µ—Å—Ç –ø—Ä–µ–º–∏–Ω–∞ —É—Å–ø–µ—à–Ω–æ! –ì–æ—Ç–æ–≤–∏ —Å–º–µ –∑–∞ —Å–ª–µ–¥–≤–∞—â–∞—Ç–∞ —Å—Ç—ä–ø–∫–∞.")
    else:
        print("\nüí° –ò–º–∞ –ø—Ä–æ–±–ª–µ–º —Å –≤—Ä—ä–∑–∫–∞—Ç–∞. –ü—Ä–æ–≤–µ—Ä–µ—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –≤—Ä—ä–∑–∫–∞—Ç–∞.")
